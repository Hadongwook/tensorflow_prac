{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 96\n",
    "image_color = 1\n",
    "batch_size = 5\n",
    "training_file_name = '/home/syso/Tensorflow/prac/training.csv'\n",
    "test_file_name = '/home/syso/Tensorflow/prac/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_queue(csv_file_name, num_epochs = None):\n",
    "    print(\"get_input_queue\")\n",
    "    csv_file = pd.read_csv(csv_file_name,sep=',',header=None)\n",
    "    csv_file = np.array(csv_file)\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for line in csv_file:\n",
    "        train_images.append(line[0])\n",
    "        train_labels.append(int(line[1]))\n",
    "    input_queue = tf.train.slice_input_producer([train_images, train_labels], shuffle = True)\n",
    "    \n",
    "    return input_queue\n",
    "\n",
    "def read_data(input_queue):\n",
    "    print(\"read_data\")\n",
    "    image_file = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    image = tf.image.decode_jpeg(tf.read_file(image_file),channels=1)\n",
    "    return image,label,image_file\n",
    "\n",
    "\n",
    "def read_data_batch(csv_file_name, batch_size = batch_size):\n",
    "    print(\"read_data_batch\")\n",
    "    input_queue = get_input_queue(csv_file_name)\n",
    "    image,label,file_name= read_data(input_queue)\n",
    "    image = tf.reshape(image,[image_size*image_size*image_color])\n",
    "    \n",
    "    batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)\n",
    "    batch_file = tf.reshape(batch_file,[batch_size,1])\n",
    "    \n",
    "    print(\"read_data_batch\")\n",
    "    \n",
    "    return batch_image,batch_label,batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = 16\n",
    "n2 = 32\n",
    "n3 = 64\n",
    "ksize = 5\n",
    "\n",
    "weights={\n",
    "    'ce1': tf.Variable(tf.random_normal([ksize,ksize,image_color,n1], stddev=0.1)),\n",
    "    'ce2': tf.Variable(tf.random_normal([ksize,ksize,n1,n2], stddev=0.1)),\n",
    "    'ce3': tf.Variable(tf.random_normal([ksize,ksize,n2,n3], stddev=0.1)),\n",
    "    'cd3': tf.Variable(tf.random_normal([ksize,ksize,n2,n3], stddev=0.1)),\n",
    "    'cd2': tf.Variable(tf.random_normal([ksize,ksize,n1,n2], stddev=0.1)),\n",
    "    'cd1': tf.Variable(tf.random_normal([ksize,ksize,image_color,n1], stddev=0.1))\n",
    "    \n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'be1': tf.Variable(tf.random_normal([n1], stddev=0.1)),\n",
    "    'be2': tf.Variable(tf.random_normal([n2], stddev=0.1)),\n",
    "    'be3': tf.Variable(tf.random_normal([n3], stddev=0.1)),\n",
    "    'bd3': tf.Variable(tf.random_normal([n2], stddev=0.1)),\n",
    "    'bd2': tf.Variable(tf.random_normal([n1], stddev=0.1)),\n",
    "    'bd1': tf.Variable(tf.random_normal([1], stddev=0.1))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cae(_X, _W, _b, _keepprob):\n",
    "    _input_r = tf.reshape(_X,shape=[-1, image_size,image_size,image_color])\n",
    "    #encode\n",
    "    _ce1 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_input_r,_W['ce1'],strides=[1,2,2,1], padding='SAME'),_b['be1']))\n",
    "    _ce1 = tf.nn.dropout(_ce1,_keepprob)\n",
    "    _ce2 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce1,_W['ce2'],strides=[1,2,2,1], padding='SAME'),_b['be2']))\n",
    "    _ce2 = tf.nn.dropout(_ce2, _keepprob)\n",
    "    _ce3 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce2,_W['ce3'],strides=[1,2,2,1], padding='SAME'),_b['be3']))\n",
    "    _ce1 = tf.nn.dropout(_ce3,_keepprob)\n",
    "    \n",
    "    #decode\n",
    "    _cd3 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_ce3,_W['cd3'],tf.stack([tf.shape(_X)[0],24, 24, n2]), strides=[1, 2, 2, 1],\n",
    "                               padding='SAME'),_b['bd3']))\n",
    "    _cd3 = tf.nn.dropout(_cd3, _keepprob)\n",
    "    _cd2 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_cd3,_W['cd2'], tf.stack([tf.shape(_X)[0], 48, 48, n1]), strides=[1,2,2,1],\n",
    "                                                      padding='SAME'), _b['bd2']))\n",
    "    _cd2 = tf.nn.dropout(_cd2, _keepprob)\n",
    "    _cd1 = tf.nn.sigmoid(tf.add(tf.nn.conv2d_transpose(_cd2,_W['cd1'], tf.stack([tf.shape(_X)[0],96,96,1]), strides=[1,2,2,1],\n",
    "                                                      padding='SAME'), _b['bd1']))\n",
    "    _cd1 = tf.nn.dropout(_cd1, _keepprob)\n",
    "    _out = _cd1\n",
    "    return {'input_r': _input_r, 'ce1':_ce1, 'ce2': _ce2, 'ce3': _ce3, 'cd3':_cd3, 'cd2': _cd2, 'cd1':_cd1,\n",
    "            'layers':(_input_r, _ce1, _ce2, _ce3, _cd3, _cd2, _cd1), 'out':_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, image_size*image_size])\n",
    "y = tf.placeholder(tf.float32, [None, image_size*image_size])\n",
    "print(x)\n",
    "keepprob = tf.placeholder(tf.float32)\n",
    "pred = cae(x, weights, biases, keepprob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(cae(x, weights, biases, keepprob)['out']-tf.reshape(y,shape=[-1,image_size,image_size, image_color])))\n",
    "cost = tf.reduce_mean(tf.square(tf.reshape(cae(x, weights, biases, keepprob)['out'], shape=[-1,1]) - tf.reshape(y,shape=[-1,1])))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optm = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mean_img = np.zeros((image_size*image_size))\n",
    "batch_xs, _, _ = read_data_batch(training_file_name)\n",
    "test_xs, _, _ = read_data_batch(test_file_name)\n",
    "n_epochs   = 5000\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_i in range(n_epochs):\n",
    "\n",
    "    for batch_i in range(8//batch_size):\n",
    "        batch_xs_ = sess.run(batch_xs)\n",
    "        print('batch_xs')\n",
    "        trainbatch = np.array([img - mean_img for img in batch_xs_])\n",
    "        #print(trainbatch[0])\n",
    "        #plt.imshow(trainbatch[0].reshape(96,96), cmap='Greys', interpolation='nearest')\n",
    "        #plt.show()\n",
    "        trainbatch_noisy = trainbatch - 10*np.random.randn(trainbatch.shape[0], image_size*image_size)\n",
    "        #print(trainbatch[0])\n",
    "        #plt.imshow(trainbatch_noisy[0].reshape(96,96), cmap='Greys', interpolation='nearest')\n",
    "        #plt.show()\n",
    "        print('run...')\n",
    "        sess.run(optm, feed_dict={x:trainbatch_noisy, y:trainbatch, keepprob:0.7})\n",
    "        \n",
    "        print (\"[%02d/%02d] cost: %.4f\" % (epoch_i, n_epochs, sess.run(cost, feed_dict={x: trainbatch_noisy, y: trainbatch, keepprob: 1.})))\n",
    "        \n",
    "        if (epoch_i % 1) == 0:\n",
    "                        \n",
    "            test_xs_ = sess.run(test_xs)\n",
    "            print('test_xs')\n",
    "            test_xs_noisy = test_xs_ + 10*np.random.randn(test_xs_.shape[0], image_size*image_size)\n",
    "            recon = sess.run(pred, feed_dict={x: test_xs_noisy, keepprob: 1.})\n",
    "            #print(recon)            \n",
    "            #plt.subplots(2, 2)\n",
    "            _, axs = plt.subplots(2,2)\n",
    "            axs[0][0].matshow(np.reshape(trainbatch[0],(96,96)), cmap=plt.get_cmap('gray'))\n",
    "            axs[0][1].matshow(np.reshape(test_xs_noisy[0],(96,96)), cmap=plt.get_cmap('gray'))\n",
    "            axs[1][0].matshow(np.reshape(trainbatch_noisy[0],(96,96)), cmap=plt.get_cmap('gray'))\n",
    "            axs[1][1].matshow(np.reshape(recon['out'][0],(96,96)), cmap=plt.get_cmap('gray'))\n",
    "            #plt.imshow(test_xs_noisy[0].reshape(96,96).reshape(96,96), cmap='Greys', interpolation='nearest')\n",
    "            #plt.show()\n",
    "            #plt.imshow(recon['out'][0].reshape(96,96).reshape(96,96), cmap='Greys', interpolation='nearest')\n",
    "            plt.show()\n",
    "                \n",
    "            \n",
    "            \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_xs_ = sess.run(test_xs)\n",
    "\n",
    "tt = sess.run(pred, feed_dict={x: test_xs_, keepprob: 1.})\n",
    "plt.imshow(tt['out'][0].reshape(96,96).reshape(96,96), cmap=plt.get_cmap('gray'), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = tt['layers']\n",
    "for i in range(len(layers)):\n",
    "    currl = layers[i]\n",
    "    print ((\"Shape of layer %d is %s\") % (i+1, currl.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
